================================================================================
QUICK START GUIDE - Distributed ML Training Demo
================================================================================

PROJECT: /workspace/Bara/notebooks/orchestration

WHAT IT DOES:
- Trains ResNet50 on CIFAR-10 dataset
- Uses 4 Docker containers (simulating 4 servers)
- Each container uses 1 GPU
- PyTorch Distributed Data Parallel (DDP) training
- Automatic checkpointing and logging

REQUIREMENTS:
- Docker & Docker Compose installed
- NVIDIA GPU(s) with CUDA support
- NVIDIA Container Toolkit installed
- At least 4 GPUs (one per container)

================================================================================
HOW TO RUN (SIMPLE):
================================================================================

1. Navigate to the project:
   cd /workspace/Bara/notebooks/orchestration

2. Run the demo:
   ./run_training_docker.sh

   OR manually:
   docker-compose up --build

3. Watch the logs:
   docker-compose logs -f

4. Stop when done:
   docker-compose down

================================================================================
WHAT HAPPENS:
================================================================================

1. Builds Docker image with PyTorch, CUDA, and training code
2. Starts 4 containers:
   - ml-worker-0 (Master, Rank 0)
   - ml-worker-1 (Rank 1)
   - ml-worker-2 (Rank 2)
   - ml-worker-3 (Rank 3)

3. Each container:
   - Gets assigned 1 GPU
   - Downloads CIFAR-10 dataset (first run)
   - Trains ResNet50 with distributed training
   - Saves checkpoints and logs

4. Training runs for 100 epochs by default
   - Checkpoints saved to: ./checkpoints/
   - Logs saved to: ./logs/
   - Dataset stored in: ./data/

================================================================================
MONITORING:
================================================================================

View logs in real-time:
  docker-compose logs -f

View specific worker:
  docker logs -f ml-worker-0

Check container status:
  docker-compose ps

Check GPU usage:
  nvidia-smi

================================================================================
CUSTOMIZATION:
================================================================================

Edit config.json to change:
- Model: "resnet50" or "simplecnn"
- Batch size: 32 (default)
- Learning rate: 0.1
- Number of epochs: 100
- Dataset: "cifar10"

================================================================================
TROUBLESHOOTING:
================================================================================

Issue: No GPUs detected
  Fix: Install NVIDIA Container Toolkit
    sudo apt-get install nvidia-container-toolkit
    sudo systemctl restart docker

Issue: Containers won't start
  Check: docker --version (needs >= 19.03)
  Check: nvidia-smi (verify GPUs)

Issue: Permission denied
  Fix: chmod +x run_training_docker.sh

Issue: Out of memory
  Fix: Reduce batch size in config.json
  Or: Use fewer containers (edit docker-compose.yml)

================================================================================
FILES:
================================================================================

Key files:
- docker-compose.yml     # Container orchestration
- Dockerfile             # Container image
- slurm_training_demo.py # Training script
- config.json           # All parameters
- run_training_docker.sh # Easy start script
- HOW_TO_DEMO.md        # Detailed guide

================================================================================
EXPECTED OUTPUT:
================================================================================

You should see logs like:
  âœ“ Distributed training initialized on rank 0 using nccl
  âœ“ Model setup complete on rank 0 - resnet50
  Epoch: 0, Batch: 0, Loss: 2.3012, Acc: 10.94%
  ðŸ“Š Epoch 0 - Train Acc: 29.94%, Val Acc: 43.40%
  âœ“ Checkpoint saved: checkpoints/checkpoint_epoch_0.pth

================================================================================
For more details, see: HOW_TO_DEMO.md
================================================================================

